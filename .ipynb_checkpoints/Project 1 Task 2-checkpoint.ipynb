{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0: Define a Naive Bayes' Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have\n",
    "$$ P(word\\,|\\,class) = \\frac{c(word\\,in\\,class)}{c(all\\,words\\,in\\,that\\,class)}$$\n",
    "## What we need\n",
    "$$ P(class\\,|\\,word) $$\n",
    "$$ \\rightarrow \\frac{P(word\\,|\\,class) * P(class)}{P(word)} $$\n",
    "## How to choose a class ?\n",
    "$$class = argmax_i\\,P(class_i\\,|\\,word)$$\n",
    "$$ \\rightarrow argmax_i \\, \\frac{P(word\\,|\\,class_i) * P(class_i)}{P(word)} $$\n",
    "$$ \\rightarrow argmax_i \\, P(word\\,|\\,class_i) * P(class_i) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get Imports and Dependencies\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk import ngrams, FreqDist\n",
    "import re\n",
    "\n",
    "corpus_files = sorted(os.listdir('./Data'))\n",
    "#print(corpus_files)\n",
    "\n",
    "f = open('./Data/train.txt', 'r')\n",
    "training_data = []\n",
    "for line in f:\n",
    "    training_data.append(f.readline())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function collects the data for the Naive Bayes' Classifier. \n",
    "# The data collected includes the errenous word, the type of error and the correction.\n",
    "# The count of the error type is also calculated, and given the word and error type\n",
    "# Given the word and the error type, the corrections are also calculated\n",
    "from operator import itemgetter\n",
    "\n",
    "wrong_word_count = dict() # {wrong_word: count}\n",
    "error_count = dict() # {error_type: count}\n",
    "wrong_word_error_count = dict() #{(wrong_word, error_type): count}\n",
    "error_types = list()\n",
    "\n",
    "sorted_wrong_word_count = list()\n",
    "sorted_error_count = list() \n",
    "sorted_wrong_word_error_count = list() \n",
    "\n",
    "def get_error_counts(file):\n",
    "    # wrong_word_context = dict() #{wrong_word: [(two_words_before), (two_words_after)]}\n",
    "    \n",
    "    for line in file:\n",
    "        if \" \" in line:\n",
    "            spl = line.split()\n",
    "            word = spl[0]\n",
    "            if word not in wrong_word_count:\n",
    "                wrong_word_count[word] = 0\n",
    "            wrong_word_count[word] += 1\n",
    "            \n",
    "            err = spl[len(spl)-1]\n",
    "            if err not in error_types:\n",
    "                error_types.append(err)\n",
    "                error_count[err] = 0\n",
    "            error_count[err] += 1\n",
    "            \n",
    "            size = len(spl)\n",
    "            if size > 1:\n",
    "                spl[1:size-1] = [' '.join(spl[1:size-1])]\n",
    "            \n",
    "            if (word, err) not in wrong_word_error_count:\n",
    "                wrong_word_error_count[(word, err)] = 0\n",
    "            wrong_word_error_count[(word, err)] += 1\n",
    "    for key, value in sorted(wrong_word_count.items(), key = itemgetter(1), reverse = True):\n",
    "        #print ((key, value))\n",
    "        sorted_wrong_word_count.append((key, value))\n",
    "    for key, value in sorted(error_count.items(), key = itemgetter(1), reverse = True):\n",
    "        sorted_error_count.append((key, value))\n",
    "    for key, value in sorted(wrong_word_error_count.items(), key = itemgetter(1), reverse = True):\n",
    "        sorted_wrong_word_error_count.append(((key), value))\n",
    "    \n",
    "    return \n",
    "\n",
    "def get_probabs(file):\n",
    "    get_error_counts(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skew in the Classes\n",
    "* What if one class/genre has the biggest corpus ?.\n",
    "* How to manage this skew ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative : A Class of Models \n",
    "* $P(Class\\,|\\,Data)$ is estimated by figuring out $P(Data\\,|\\,Class)$\n",
    "* The model tries to ask, What is the chance that, I have seen this data if it came from this particular class ?.\n",
    "* The model therefore, **generates** data, or more accurately, generates its estimate of the data. So, its a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
